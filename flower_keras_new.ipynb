{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flower keras new.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayedmohamedscu/flower-classification-keras/blob/master/flower_keras_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "2GQlUX-XDpia",
        "colab_type": "code",
        "outputId": "88059d94-eb18-4317-8e62-dca917439cdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dense,GlobalAveragePooling2D\n",
        "from keras.applications import MobileNet\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "L0qTBo9KD3co",
        "colab_type": "code",
        "outputId": "cc8ffa4b-f0bf-4278-8c24-41cb7a805e45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "base_model=MobileNet(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
        "\n",
        "x=base_model.output\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
        "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
        "x=Dense(512,activation='relu')(x) #dense layer 3\n",
        "preds=Dense(102,activation='softmax')(x) #final layer with softmax activation"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet.py:208: UserWarning: MobileNet shape is undefined. Weights for input shape (224, 224) will be loaded.\n",
            "  warnings.warn('MobileNet shape is undefined.'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "DK7njcmBEYZK",
        "colab_type": "code",
        "outputId": "f3a920a2-edbf-4cc9-bcd3-e13d223bca6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3525
        }
      },
      "cell_type": "code",
      "source": [
        "model=Model(inputs=base_model.input,outputs=preds)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, None, None, 3)     0         \n",
            "_________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)    (None, None, None, 3)     0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, None, None, 32)    864       \n",
            "_________________________________________________________________\n",
            "conv1_bn (BatchNormalization (None, None, None, 32)    128       \n",
            "_________________________________________________________________\n",
            "conv1_relu (ReLU)            (None, None, None, 32)    0         \n",
            "_________________________________________________________________\n",
            "conv_dw_1 (DepthwiseConv2D)  (None, None, None, 32)    288       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_bn (BatchNormaliza (None, None, None, 32)    128       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_relu (ReLU)        (None, None, None, 32)    0         \n",
            "_________________________________________________________________\n",
            "conv_pw_1 (Conv2D)           (None, None, None, 64)    2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_1_bn (BatchNormaliza (None, None, None, 64)    256       \n",
            "_________________________________________________________________\n",
            "conv_pw_1_relu (ReLU)        (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "conv_pad_2 (ZeroPadding2D)   (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "conv_dw_2 (DepthwiseConv2D)  (None, None, None, 64)    576       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_bn (BatchNormaliza (None, None, None, 64)    256       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_relu (ReLU)        (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "conv_pw_2 (Conv2D)           (None, None, None, 128)   8192      \n",
            "_________________________________________________________________\n",
            "conv_pw_2_bn (BatchNormaliza (None, None, None, 128)   512       \n",
            "_________________________________________________________________\n",
            "conv_pw_2_relu (ReLU)        (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_3 (DepthwiseConv2D)  (None, None, None, 128)   1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_3_bn (BatchNormaliza (None, None, None, 128)   512       \n",
            "_________________________________________________________________\n",
            "conv_dw_3_relu (ReLU)        (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_3 (Conv2D)           (None, None, None, 128)   16384     \n",
            "_________________________________________________________________\n",
            "conv_pw_3_bn (BatchNormaliza (None, None, None, 128)   512       \n",
            "_________________________________________________________________\n",
            "conv_pw_3_relu (ReLU)        (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "conv_pad_4 (ZeroPadding2D)   (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_4 (DepthwiseConv2D)  (None, None, None, 128)   1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_4_bn (BatchNormaliza (None, None, None, 128)   512       \n",
            "_________________________________________________________________\n",
            "conv_dw_4_relu (ReLU)        (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_4 (Conv2D)           (None, None, None, 256)   32768     \n",
            "_________________________________________________________________\n",
            "conv_pw_4_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_4_relu (ReLU)        (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_5 (DepthwiseConv2D)  (None, None, None, 256)   2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_relu (ReLU)        (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_5 (Conv2D)           (None, None, None, 256)   65536     \n",
            "_________________________________________________________________\n",
            "conv_pw_5_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_5_relu (ReLU)        (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "conv_pad_6 (ZeroPadding2D)   (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_6 (DepthwiseConv2D)  (None, None, None, 256)   2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_relu (ReLU)        (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_6 (Conv2D)           (None, None, None, 512)   131072    \n",
            "_________________________________________________________________\n",
            "conv_pw_6_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_6_relu (ReLU)        (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_7 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_relu (ReLU)        (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_7 (Conv2D)           (None, None, None, 512)   262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_7_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_7_relu (ReLU)        (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_8 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_relu (ReLU)        (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_8 (Conv2D)           (None, None, None, 512)   262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_8_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_8_relu (ReLU)        (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_9 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_relu (ReLU)        (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_9 (Conv2D)           (None, None, None, 512)   262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_9_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_9_relu (ReLU)        (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_10 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_relu (ReLU)       (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_10 (Conv2D)          (None, None, None, 512)   262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_10_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_10_relu (ReLU)       (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_11 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_relu (ReLU)       (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_11 (Conv2D)          (None, None, None, 512)   262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_11_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_11_relu (ReLU)       (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_pad_12 (ZeroPadding2D)  (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_12 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_relu (ReLU)       (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_12 (Conv2D)          (None, None, None, 1024)  524288    \n",
            "_________________________________________________________________\n",
            "conv_pw_12_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_12_relu (ReLU)       (None, None, None, 1024)  0         \n",
            "_________________________________________________________________\n",
            "conv_dw_13 (DepthwiseConv2D) (None, None, None, 1024)  9216      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_relu (ReLU)       (None, None, None, 1024)  0         \n",
            "_________________________________________________________________\n",
            "conv_pw_13 (Conv2D)          (None, None, None, 1024)  1048576   \n",
            "_________________________________________________________________\n",
            "conv_pw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_13_relu (ReLU)       (None, None, None, 1024)  0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 102)               52326     \n",
            "=================================================================\n",
            "Total params: 5,905,190\n",
            "Trainable params: 5,883,302\n",
            "Non-trainable params: 21,888\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qD0nBFKPEZoG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for layer in model.layers[:75]:\n",
        "    layer.trainable=False\n",
        "for layer in model.layers[75:]:\n",
        "    layer.trainable=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "del_IMwmEnRk",
        "colab_type": "code",
        "outputId": "49c53473-6454-49a9-dd88-d2b58cd3ea83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "cell_type": "code",
      "source": [
        "!wget -O cat_to_name.json \"https://raw.githubusercontent.com/GabrielePicco/deep-learning-flower-identifier/master/cat_to_name.json\"\n",
        "!wget \"https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip\" \n",
        "!unzip flower_data.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-02 20:42:59--  https://raw.githubusercontent.com/GabrielePicco/deep-learning-flower-identifier/master/cat_to_name.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2218 (2.2K) [text/plain]\n",
            "Saving to: ‘cat_to_name.json’\n",
            "\n",
            "\rcat_to_name.json      0%[                    ]       0  --.-KB/s               \rcat_to_name.json    100%[===================>]   2.17K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-03-02 20:42:59 (45.8 MB/s) - ‘cat_to_name.json’ saved [2218/2218]\n",
            "\n",
            "--2019-03-02 20:43:01--  https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.85.181\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.85.181|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 311442766 (297M) [application/zip]\n",
            "Saving to: ‘flower_data.zip.1’\n",
            "\n",
            "flower_data.zip.1   100%[===================>] 297.01M  92.0MB/s    in 3.4s    \n",
            "\n",
            "2019-03-02 20:43:05 (86.6 MB/s) - ‘flower_data.zip.1’ saved [311442766/311442766]\n",
            "\n",
            "Archive:  flower_data.zip\n",
            "replace flower_data/valid/61/image_06296.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_q9CiVqAEr5V",
        "colab_type": "code",
        "outputId": "2d23c023-491c-42df-cc89-40ce4d5a21dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cat_to_name.json  flower_data.zip    flowernew.h5\n",
            "flower_data\t  flower_data.zip.1  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-IyS9wswEt8L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "rescale = 1./255,\n",
        "horizontal_flip = True,\n",
        "fill_mode = \"nearest\",\n",
        "zoom_range = 0.3,\n",
        "width_shift_range = 0.3,\n",
        "height_shift_range=0.3,\n",
        "rotation_range=30)\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "rescale = 1./255,\n",
        "horizontal_flip = True,\n",
        "fill_mode = \"nearest\",\n",
        "zoom_range = 0.3,\n",
        "width_shift_range = 0.3,\n",
        "height_shift_range=0.3,\n",
        "rotation_range=30)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DV5SKDFhFK8-",
        "colab_type": "code",
        "outputId": "15defc22-8971-4a63-cf0a-ec75a9e1e21f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "train_generator=train_datagen.flow_from_directory('/content/flower_data/train', # this is where you specify the path to the main data folder\n",
        "                                                 target_size=(224,224),\n",
        "                                                 color_mode='rgb',\n",
        "                                                 batch_size=32,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 shuffle=True)\n",
        "test_generator=test_datagen.flow_from_directory('/content/flower_data/valid', # this is where you specify the path to the main data folder\n",
        "                                                 target_size=(224,224),\n",
        "                                                 color_mode='rgb',\n",
        "                                                 batch_size=32,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6552 images belonging to 102 classes.\n",
            "Found 818 images belonging to 102 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y39yC8-oFXcj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
        "\n",
        "from keras.callbacks import History \n",
        "history = History()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uC8Ao5ySH0FC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(\"flower2new.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fAPY13aCH9Mq",
        "colab_type": "code",
        "outputId": "9c600af3-bc3a-44a8-df94-8f2def053fdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3690
        }
      },
      "cell_type": "code",
      "source": [
        "#model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "# Adam optimizer\n",
        "# loss function will be categorical cross entropy\n",
        "# evaluation metric will be accuracy\n",
        "\n",
        "from keras import optimizers\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-5),\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=100,\n",
        "      validation_data=test_generator,\n",
        "      validation_steps=50)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 95s 947ms/step - loss: 4.5963 - acc: 0.0247 - val_loss: 4.4875 - val_acc: 0.0555\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 83s 833ms/step - loss: 4.3575 - acc: 0.0813 - val_loss: 4.3176 - val_acc: 0.1170\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 85s 854ms/step - loss: 4.1095 - acc: 0.1563 - val_loss: 4.1526 - val_acc: 0.1908\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 84s 840ms/step - loss: 3.8811 - acc: 0.2203 - val_loss: 3.9479 - val_acc: 0.2182\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 84s 836ms/step - loss: 3.5892 - acc: 0.2849 - val_loss: 3.7158 - val_acc: 0.2551\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 83s 834ms/step - loss: 3.2482 - acc: 0.3425 - val_loss: 3.4485 - val_acc: 0.3015\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 84s 840ms/step - loss: 2.8654 - acc: 0.4206 - val_loss: 3.2135 - val_acc: 0.2996\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 85s 846ms/step - loss: 2.6373 - acc: 0.4566 - val_loss: 2.9500 - val_acc: 0.3836\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 83s 828ms/step - loss: 2.3471 - acc: 0.5258 - val_loss: 2.7435 - val_acc: 0.4059\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 82s 824ms/step - loss: 2.0569 - acc: 0.5950 - val_loss: 2.5958 - val_acc: 0.4294\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 84s 840ms/step - loss: 1.8265 - acc: 0.6453 - val_loss: 2.3903 - val_acc: 0.4676\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 82s 817ms/step - loss: 1.5930 - acc: 0.7031 - val_loss: 2.1752 - val_acc: 0.5140\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 84s 845ms/step - loss: 1.4323 - acc: 0.7217 - val_loss: 1.9977 - val_acc: 0.5490\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 85s 849ms/step - loss: 1.2880 - acc: 0.7488 - val_loss: 1.9354 - val_acc: 0.5618\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 83s 832ms/step - loss: 1.1023 - acc: 0.7915 - val_loss: 1.7521 - val_acc: 0.5795\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 83s 827ms/step - loss: 1.0580 - acc: 0.7872 - val_loss: 1.6958 - val_acc: 0.5751\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 84s 842ms/step - loss: 0.9552 - acc: 0.8095 - val_loss: 1.5959 - val_acc: 0.6062\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 83s 830ms/step - loss: 0.8673 - acc: 0.8356 - val_loss: 1.5124 - val_acc: 0.6253\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 84s 842ms/step - loss: 0.7575 - acc: 0.8476 - val_loss: 1.3849 - val_acc: 0.6539\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 82s 822ms/step - loss: 0.7265 - acc: 0.8466 - val_loss: 1.4101 - val_acc: 0.6368\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 82s 824ms/step - loss: 0.6421 - acc: 0.8683 - val_loss: 1.3001 - val_acc: 0.6692\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 85s 850ms/step - loss: 0.6194 - acc: 0.8750 - val_loss: 1.3224 - val_acc: 0.6469\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 84s 836ms/step - loss: 0.5781 - acc: 0.8846 - val_loss: 1.1896 - val_acc: 0.6966\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 83s 828ms/step - loss: 0.5369 - acc: 0.8909 - val_loss: 1.1956 - val_acc: 0.6902\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 85s 849ms/step - loss: 0.5223 - acc: 0.8934 - val_loss: 1.1545 - val_acc: 0.6902\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 84s 836ms/step - loss: 0.4553 - acc: 0.9056 - val_loss: 1.1283 - val_acc: 0.7080\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 84s 837ms/step - loss: 0.4347 - acc: 0.9132 - val_loss: 1.1072 - val_acc: 0.6992\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 85s 850ms/step - loss: 0.4042 - acc: 0.9166 - val_loss: 1.0896 - val_acc: 0.7061\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 84s 836ms/step - loss: 0.3973 - acc: 0.9177 - val_loss: 1.0607 - val_acc: 0.7137\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 82s 825ms/step - loss: 0.3820 - acc: 0.9194 - val_loss: 0.9816 - val_acc: 0.7309\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - 84s 841ms/step - loss: 0.3684 - acc: 0.9220 - val_loss: 1.0659 - val_acc: 0.7061\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - 85s 847ms/step - loss: 0.3509 - acc: 0.9262 - val_loss: 1.0105 - val_acc: 0.7163\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - 83s 834ms/step - loss: 0.3213 - acc: 0.9359 - val_loss: 0.9623 - val_acc: 0.7271\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - 84s 843ms/step - loss: 0.3202 - acc: 0.9287 - val_loss: 0.9610 - val_acc: 0.7335\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - 84s 840ms/step - loss: 0.2976 - acc: 0.9329 - val_loss: 0.9879 - val_acc: 0.7303\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - 83s 829ms/step - loss: 0.2864 - acc: 0.9394 - val_loss: 0.9541 - val_acc: 0.7271\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - 85s 847ms/step - loss: 0.3049 - acc: 0.9329 - val_loss: 0.8885 - val_acc: 0.7455\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - 85s 853ms/step - loss: 0.2641 - acc: 0.9437 - val_loss: 0.8741 - val_acc: 0.7506\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - 83s 834ms/step - loss: 0.2668 - acc: 0.9387 - val_loss: 0.8945 - val_acc: 0.7513\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - 82s 824ms/step - loss: 0.2630 - acc: 0.9431 - val_loss: 0.8560 - val_acc: 0.7623\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - 85s 855ms/step - loss: 0.2290 - acc: 0.9511 - val_loss: 0.8657 - val_acc: 0.7500\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - 82s 815ms/step - loss: 0.2229 - acc: 0.9534 - val_loss: 0.8444 - val_acc: 0.7704\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - 83s 834ms/step - loss: 0.2200 - acc: 0.9534 - val_loss: 0.8077 - val_acc: 0.7735\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - 85s 851ms/step - loss: 0.2160 - acc: 0.9551 - val_loss: 0.8176 - val_acc: 0.7786\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - 83s 835ms/step - loss: 0.2208 - acc: 0.9491 - val_loss: 0.7930 - val_acc: 0.7812\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - 81s 807ms/step - loss: 0.2007 - acc: 0.9546 - val_loss: 0.8000 - val_acc: 0.7646\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - 84s 839ms/step - loss: 0.2023 - acc: 0.9584 - val_loss: 0.8105 - val_acc: 0.7557\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - 83s 829ms/step - loss: 0.1804 - acc: 0.9607 - val_loss: 0.7854 - val_acc: 0.7748\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - 82s 825ms/step - loss: 0.1952 - acc: 0.9584 - val_loss: 0.7642 - val_acc: 0.7748\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - 81s 811ms/step - loss: 0.1960 - acc: 0.9553 - val_loss: 0.7667 - val_acc: 0.7678\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - 83s 827ms/step - loss: 0.1748 - acc: 0.9641 - val_loss: 0.7591 - val_acc: 0.7831\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - 84s 844ms/step - loss: 0.1701 - acc: 0.9635 - val_loss: 0.7301 - val_acc: 0.7863\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - 83s 833ms/step - loss: 0.1605 - acc: 0.9634 - val_loss: 0.7995 - val_acc: 0.7654\n",
            "Epoch 54/100\n",
            "100/100 [==============================] - 84s 843ms/step - loss: 0.1541 - acc: 0.9653 - val_loss: 0.6840 - val_acc: 0.8022\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - 83s 832ms/step - loss: 0.1720 - acc: 0.9600 - val_loss: 0.7571 - val_acc: 0.7805\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - 81s 809ms/step - loss: 0.1574 - acc: 0.9633 - val_loss: 0.7875 - val_acc: 0.7723\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - 83s 830ms/step - loss: 0.1413 - acc: 0.9672 - val_loss: 0.6932 - val_acc: 0.8073\n",
            "Epoch 58/100\n",
            "100/100 [==============================] - 84s 842ms/step - loss: 0.1369 - acc: 0.9718 - val_loss: 0.7001 - val_acc: 0.7939\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - 86s 856ms/step - loss: 0.1422 - acc: 0.9663 - val_loss: 0.6838 - val_acc: 0.8104\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - 82s 820ms/step - loss: 0.1372 - acc: 0.9718 - val_loss: 0.6830 - val_acc: 0.8092\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - 83s 832ms/step - loss: 0.1165 - acc: 0.9753 - val_loss: 0.6760 - val_acc: 0.8142\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - 76s 764ms/step - loss: 0.1232 - acc: 0.9712 - val_loss: 0.7294 - val_acc: 0.7996\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - 77s 773ms/step - loss: 0.1298 - acc: 0.9694 - val_loss: 0.6718 - val_acc: 0.8200\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - 81s 809ms/step - loss: 0.1125 - acc: 0.9756 - val_loss: 0.6893 - val_acc: 0.8009\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - 80s 801ms/step - loss: 0.1127 - acc: 0.9750 - val_loss: 0.6610 - val_acc: 0.8117\n",
            "Epoch 66/100\n",
            "100/100 [==============================] - 77s 770ms/step - loss: 0.1308 - acc: 0.9684 - val_loss: 0.6473 - val_acc: 0.8064\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - 80s 796ms/step - loss: 0.1174 - acc: 0.9762 - val_loss: 0.6236 - val_acc: 0.8238\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - 79s 788ms/step - loss: 0.0930 - acc: 0.9816 - val_loss: 0.6215 - val_acc: 0.8193\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - 78s 780ms/step - loss: 0.1111 - acc: 0.9750 - val_loss: 0.6691 - val_acc: 0.8073\n",
            "Epoch 70/100\n",
            "100/100 [==============================] - 81s 809ms/step - loss: 0.0984 - acc: 0.9806 - val_loss: 0.6696 - val_acc: 0.8060\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - 79s 789ms/step - loss: 0.1075 - acc: 0.9744 - val_loss: 0.6816 - val_acc: 0.8130\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - 76s 761ms/step - loss: 0.1017 - acc: 0.9750 - val_loss: 0.5887 - val_acc: 0.8232\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - 79s 790ms/step - loss: 0.0971 - acc: 0.9759 - val_loss: 0.6824 - val_acc: 0.7990\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - 82s 816ms/step - loss: 0.0925 - acc: 0.9812 - val_loss: 0.6142 - val_acc: 0.8142\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - 76s 760ms/step - loss: 0.0938 - acc: 0.9781 - val_loss: 0.6416 - val_acc: 0.8168\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - 76s 760ms/step - loss: 0.0972 - acc: 0.9803 - val_loss: 0.6001 - val_acc: 0.8238\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - 81s 811ms/step - loss: 0.0896 - acc: 0.9813 - val_loss: 0.6948 - val_acc: 0.7990\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - 79s 791ms/step - loss: 0.0847 - acc: 0.9799 - val_loss: 0.6527 - val_acc: 0.8073\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - 76s 757ms/step - loss: 0.0823 - acc: 0.9856 - val_loss: 0.5908 - val_acc: 0.8228\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - 77s 772ms/step - loss: 0.0890 - acc: 0.9766 - val_loss: 0.6323 - val_acc: 0.8181\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - 82s 816ms/step - loss: 0.0815 - acc: 0.9825 - val_loss: 0.6290 - val_acc: 0.8136\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - 78s 783ms/step - loss: 0.0869 - acc: 0.9787 - val_loss: 0.6309 - val_acc: 0.8162\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - 77s 768ms/step - loss: 0.0792 - acc: 0.9844 - val_loss: 0.5877 - val_acc: 0.8181\n",
            "Epoch 84/100\n",
            "100/100 [==============================] - 81s 813ms/step - loss: 0.0707 - acc: 0.9862 - val_loss: 0.6002 - val_acc: 0.8130\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - 80s 798ms/step - loss: 0.0781 - acc: 0.9824 - val_loss: 0.5603 - val_acc: 0.8327\n",
            "Epoch 86/100\n",
            "100/100 [==============================] - 76s 761ms/step - loss: 0.0791 - acc: 0.9831 - val_loss: 0.5828 - val_acc: 0.8314\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - 79s 785ms/step - loss: 0.0807 - acc: 0.9802 - val_loss: 0.5710 - val_acc: 0.8308\n",
            "Epoch 88/100\n",
            "100/100 [==============================] - 81s 810ms/step - loss: 0.0778 - acc: 0.9819 - val_loss: 0.6254 - val_acc: 0.8168\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - 76s 762ms/step - loss: 0.0702 - acc: 0.9847 - val_loss: 0.6306 - val_acc: 0.8117\n",
            "Epoch 90/100\n",
            "100/100 [==============================] - 77s 769ms/step - loss: 0.0656 - acc: 0.9844 - val_loss: 0.5572 - val_acc: 0.8454\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - 80s 800ms/step - loss: 0.0666 - acc: 0.9861 - val_loss: 0.5866 - val_acc: 0.8346\n",
            "Epoch 92/100\n",
            "100/100 [==============================] - 80s 799ms/step - loss: 0.0680 - acc: 0.9850 - val_loss: 0.5734 - val_acc: 0.8298\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - 76s 763ms/step - loss: 0.0643 - acc: 0.9881 - val_loss: 0.5160 - val_acc: 0.8505\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - 78s 784ms/step - loss: 0.0681 - acc: 0.9831 - val_loss: 0.5553 - val_acc: 0.8461\n",
            "Epoch 95/100\n",
            "100/100 [==============================] - 81s 815ms/step - loss: 0.0607 - acc: 0.9855 - val_loss: 0.5869 - val_acc: 0.8302\n",
            "Epoch 96/100\n",
            "100/100 [==============================] - 76s 761ms/step - loss: 0.0583 - acc: 0.9866 - val_loss: 0.5884 - val_acc: 0.8352\n",
            "Epoch 97/100\n",
            "100/100 [==============================] - 77s 769ms/step - loss: 0.0635 - acc: 0.9858 - val_loss: 0.5531 - val_acc: 0.8372\n",
            "Epoch 98/100\n",
            "100/100 [==============================] - 80s 802ms/step - loss: 0.0601 - acc: 0.9881 - val_loss: 0.5388 - val_acc: 0.8467\n",
            "Epoch 99/100\n",
            "100/100 [==============================] - 78s 782ms/step - loss: 0.0590 - acc: 0.9872 - val_loss: 0.6242 - val_acc: 0.8219\n",
            "Epoch 100/100\n",
            "100/100 [==============================] - 75s 752ms/step - loss: 0.0571 - acc: 0.9887 - val_loss: 0.5943 - val_acc: 0.8219\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wg1vWspbxSdF",
        "colab_type": "code",
        "outputId": "bc750a65-2c3b-4569-9b0c-9eee3c01fa85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3525
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, None, None, 3)     0         \n",
            "_________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)    (None, None, None, 3)     0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, None, None, 32)    864       \n",
            "_________________________________________________________________\n",
            "conv1_bn (BatchNormalization (None, None, None, 32)    128       \n",
            "_________________________________________________________________\n",
            "conv1_relu (ReLU)            (None, None, None, 32)    0         \n",
            "_________________________________________________________________\n",
            "conv_dw_1 (DepthwiseConv2D)  (None, None, None, 32)    288       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_bn (BatchNormaliza (None, None, None, 32)    128       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_relu (ReLU)        (None, None, None, 32)    0         \n",
            "_________________________________________________________________\n",
            "conv_pw_1 (Conv2D)           (None, None, None, 64)    2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_1_bn (BatchNormaliza (None, None, None, 64)    256       \n",
            "_________________________________________________________________\n",
            "conv_pw_1_relu (ReLU)        (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "conv_pad_2 (ZeroPadding2D)   (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "conv_dw_2 (DepthwiseConv2D)  (None, None, None, 64)    576       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_bn (BatchNormaliza (None, None, None, 64)    256       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_relu (ReLU)        (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "conv_pw_2 (Conv2D)           (None, None, None, 128)   8192      \n",
            "_________________________________________________________________\n",
            "conv_pw_2_bn (BatchNormaliza (None, None, None, 128)   512       \n",
            "_________________________________________________________________\n",
            "conv_pw_2_relu (ReLU)        (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_3 (DepthwiseConv2D)  (None, None, None, 128)   1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_3_bn (BatchNormaliza (None, None, None, 128)   512       \n",
            "_________________________________________________________________\n",
            "conv_dw_3_relu (ReLU)        (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_3 (Conv2D)           (None, None, None, 128)   16384     \n",
            "_________________________________________________________________\n",
            "conv_pw_3_bn (BatchNormaliza (None, None, None, 128)   512       \n",
            "_________________________________________________________________\n",
            "conv_pw_3_relu (ReLU)        (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "conv_pad_4 (ZeroPadding2D)   (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_4 (DepthwiseConv2D)  (None, None, None, 128)   1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_4_bn (BatchNormaliza (None, None, None, 128)   512       \n",
            "_________________________________________________________________\n",
            "conv_dw_4_relu (ReLU)        (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_4 (Conv2D)           (None, None, None, 256)   32768     \n",
            "_________________________________________________________________\n",
            "conv_pw_4_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_4_relu (ReLU)        (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_5 (DepthwiseConv2D)  (None, None, None, 256)   2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_relu (ReLU)        (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_5 (Conv2D)           (None, None, None, 256)   65536     \n",
            "_________________________________________________________________\n",
            "conv_pw_5_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_5_relu (ReLU)        (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "conv_pad_6 (ZeroPadding2D)   (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_6 (DepthwiseConv2D)  (None, None, None, 256)   2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_relu (ReLU)        (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_6 (Conv2D)           (None, None, None, 512)   131072    \n",
            "_________________________________________________________________\n",
            "conv_pw_6_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_6_relu (ReLU)        (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_7 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_relu (ReLU)        (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_7 (Conv2D)           (None, None, None, 512)   262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_7_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_7_relu (ReLU)        (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_8 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_relu (ReLU)        (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_8 (Conv2D)           (None, None, None, 512)   262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_8_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_8_relu (ReLU)        (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_9 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_relu (ReLU)        (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_9 (Conv2D)           (None, None, None, 512)   262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_9_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_9_relu (ReLU)        (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_10 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_relu (ReLU)       (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_10 (Conv2D)          (None, None, None, 512)   262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_10_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_10_relu (ReLU)       (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_11 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_relu (ReLU)       (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_11 (Conv2D)          (None, None, None, 512)   262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_11_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_11_relu (ReLU)       (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_pad_12 (ZeroPadding2D)  (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_12 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_relu (ReLU)       (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_12 (Conv2D)          (None, None, None, 1024)  524288    \n",
            "_________________________________________________________________\n",
            "conv_pw_12_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_12_relu (ReLU)       (None, None, None, 1024)  0         \n",
            "_________________________________________________________________\n",
            "conv_dw_13 (DepthwiseConv2D) (None, None, None, 1024)  9216      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_relu (ReLU)       (None, None, None, 1024)  0         \n",
            "_________________________________________________________________\n",
            "conv_pw_13 (Conv2D)          (None, None, None, 1024)  1048576   \n",
            "_________________________________________________________________\n",
            "conv_pw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_13_relu (ReLU)       (None, None, None, 1024)  0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 102)               52326     \n",
            "=================================================================\n",
            "Total params: 5,905,190\n",
            "Trainable params: 4,802,150\n",
            "Non-trainable params: 1,103,040\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bN_2Z_-8yIzm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('flower85%.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}